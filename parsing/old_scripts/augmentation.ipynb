{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from maskrcnn_benchmark.structures.bounding_box import BoxList\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "from pprint import pprint\n",
    "from maskrcnn_benchmark.structures.segmentation_mask import SegmentationMask\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import random\n",
    "from PIL import Image, ImageOps, ImageEnhance, PILLOW_VERSION\n",
    "try:\n",
    "    import accimage\n",
    "except ImportError:\n",
    "    accimage = None\n",
    "import numpy as np\n",
    "import numbers\n",
    "import types\n",
    "import collections\n",
    "import warnings\n",
    "\n",
    "import torchvision.transforms.functional as transforms\n",
    "from skimage.color import grey2rgb\n",
    "\n",
    "'''\n",
    "from maskrcnn_benchmark.data.transforms.transforms import Resize\n",
    "from maskrcnn_benchmark.data.transforms.transforms import RandomHorizontalFlip\n",
    "from maskrcnn_benchmark.data.transforms.transforms import ToTensor\n",
    "from maskrcnn_benchmark.data.transforms.transforms import Normalize\n",
    "from maskrcnn_benchmark.data.transforms.transforms import Compose\n",
    "'''\n",
    "from pycocotools.coco import *\n",
    "from matplotlib.patches import Rectangle\n",
    "from math import sin, cos, radians\n",
    "import cv2\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = 20, 12\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"img_dir = '/data/proj/smFISH/Students/Max_Senftleben/files/data/20190309_aug_pop/train/'\\nimg = [img_dir + i for i in os.listdir(img_dir)]\\nfor i in img:\\n    isd = mpimg.imread(i)\\n    plt.imshow(isd)\\n    plt.axis('off')\\n    plt.show()\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''img_dir = '/data/proj/smFISH/Students/Max_Senftleben/files/data/20190309_aug_pop/train/'\n",
    "img = [img_dir + i for i in os.listdir(img_dir)]\n",
    "for i in img:\n",
    "    isd = mpimg.imread(i)\n",
    "    plt.imshow(isd)\n",
    "    plt.axis('off')\n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Box(BoxList):\n",
    "    def transpose(self, method):\n",
    "        \"\"\"\n",
    "        Transpose bounding box (flip or rotate in 90 degree steps)\n",
    "        :param method: One of :py:attr:`PIL.Image.FLIP_LEFT_RIGHT`,\n",
    "          :py:attr:`PIL.Image.FLIP_TOP_BOTTOM`, :py:attr:`PIL.Image.ROTATE_90`,\n",
    "          :py:attr:`PIL.Image.ROTATE_180`, :py:attr:`PIL.Image.ROTATE_270`,\n",
    "          :py:attr:`PIL.Image.TRANSPOSE` or :py:attr:`PIL.Image.TRANSVERSE`.\n",
    "        \"\"\"\n",
    "        if method not in (FLIP_LEFT_RIGHT, FLIP_TOP_BOTTOM, ROTATE_90):\n",
    "            raise NotImplementedError(\n",
    "                \"Only FLIP_LEFT_RIGHT and FLIP_TOP_BOTTOM implemented\"\n",
    "            )\n",
    "\n",
    "        image_width, image_height = self.size\n",
    "        xmin, ymin, xmax, ymax = self._split_into_xyxy()\n",
    "        if method == FLIP_LEFT_RIGHT:\n",
    "            TO_REMOVE = 1\n",
    "            transposed_xmin = image_width - xmax - TO_REMOVE\n",
    "            transposed_xmax = image_width - xmin - TO_REMOVE\n",
    "            transposed_ymin = ymin\n",
    "            transposed_ymax = ymax\n",
    "        elif method == FLIP_TOP_BOTTOM:\n",
    "            transposed_xmin = xmin\n",
    "            transposed_xmax = xmax\n",
    "            transposed_ymin = image_height - ymax\n",
    "            transposed_ymax = image_height - ymin\n",
    "        \n",
    "        # own to rotate of 90 degrees\n",
    "        elif method == ROTATE_90:\n",
    "            angle_rad = radians(90 % 360)\n",
    "            transposed_xmax = image_width - xmax\n",
    "            transposed_xmin = image_width - xmin\n",
    "            \n",
    "            transposed_ymax = transposed_xmax\n",
    "            transposed_ymin = transposed_xmin\n",
    "            transposed_xmax = ymax\n",
    "            transposed_xmin = ymin\n",
    "\n",
    "        transposed_boxes = torch.cat(\n",
    "            (transposed_xmin, transposed_ymin, transposed_xmax, transposed_ymax), dim=-1\n",
    "        )\n",
    "        bbox = BoxList(transposed_boxes, self.size, mode=\"xyxy\")\n",
    "        # bbox._copy_extra_fields(self)\n",
    "        for k, v in self.extra_fields.items():\n",
    "            if not isinstance(v, torch.Tensor):\n",
    "                v = v.transpose(method)\n",
    "            bbox.add_field(k, v)\n",
    "        return bbox.convert(self.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        for t in self.transforms:\n",
    "            image, target = t(image, target)\n",
    "        return image, target\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + \"(\"\n",
    "        for t in self.transforms:\n",
    "            format_string += \"\\n\"\n",
    "            format_string += \"    {0}\".format(t)\n",
    "        format_string += \"\\n)\"\n",
    "        return format_string\n",
    "\n",
    "\n",
    "class Resize(object):\n",
    "    def __init__(self, min_size, max_size):\n",
    "        if not isinstance(min_size, (list, tuple)):\n",
    "            min_size = (min_size,)\n",
    "        self.min_size = min_size\n",
    "        self.max_size = max_size\n",
    "\n",
    "    # modified from torchvision to add support for max size\n",
    "    def get_size(self, image_size):\n",
    "        w, h = image_size\n",
    "        size = random.choice(self.min_size)\n",
    "        max_size = self.max_size\n",
    "        if max_size is not None:\n",
    "            min_original_size = float(min((w, h)))\n",
    "            max_original_size = float(max((w, h)))\n",
    "            if max_original_size / min_original_size * size > max_size:\n",
    "                size = int(round(max_size * min_original_size / max_original_size))\n",
    "\n",
    "        if (w <= h and w == size) or (h <= w and h == size):\n",
    "            return (h, w)\n",
    "\n",
    "        if w < h:\n",
    "            ow = size\n",
    "            oh = int(size * h / w)\n",
    "        else:\n",
    "            oh = size\n",
    "            ow = int(size * w / h)\n",
    "\n",
    "        return (oh, ow)\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        size = self.get_size(image.size)\n",
    "        image = transforms.resize(image, size)\n",
    "        target = target.resize(image.size)\n",
    "        return image, target\n",
    "\n",
    "\n",
    "class RandomHorizontalFlip(object):\n",
    "    def __init__(self, prob=0.5):\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        if random.random() < self.prob:\n",
    "            image = transforms.hflip(image)\n",
    "            target = target.transpose(0)\n",
    "        return image, target\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, image, target):\n",
    "        return transforms.to_tensor(image), target\n",
    "\n",
    "\n",
    "class Normalize(object):\n",
    "    def __init__(self, mean, std, to_bgr255=True):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.to_bgr255 = to_bgr255\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        if self.to_bgr255:\n",
    "            image = image[[2, 1, 0]] * 255\n",
    "        image = transforms.normalize(image, mean=self.mean, std=self.std)\n",
    "        return image, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# own transformation classes\n",
    "\n",
    "class VerticalFlip(object):\n",
    "    def __init__(self, prob = 0.5):\n",
    "        self.prob = prob\n",
    "    def __call__(self, image, target):\n",
    "        if random.random() < self.prob:\n",
    "            image = transforms.vflip(image)\n",
    "            target = target.transpose(1)\n",
    "        return image, target\n",
    "\n",
    "class Rotate(object):\n",
    "    def __init__(self, prob = 0.5):\n",
    "        self.prob = prob\n",
    "    def __call__(self, image, target):\n",
    "        if random.random() < self.prob:\n",
    "            angle = random.choice([90, 180, 270])\n",
    "            print(angle)\n",
    "            image = transforms.rotate(image, angle)\n",
    "            if angle == 90:\n",
    "                target = target.transpose(2)\n",
    "            elif angle == 270:\n",
    "                target = target.transpose(3)\n",
    "            elif angle == 180:\n",
    "                target = target.transpose(4)\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_instances(img, target):\n",
    "    plt.imshow(img); plt.axis(\"off\")\n",
    "    ax = plt.gca()\n",
    "    color = []\n",
    "    polygons = []\n",
    "    \n",
    "    polys = (vars(target)['extra_fields']['masks'])\n",
    "    for b in polys:\n",
    "        tenso = vars(b)['polygons'][0]\n",
    "    \n",
    "        c = (np.random.random((1, 3))*0.6+0.4).tolist()[0]\n",
    "        poly1 = tenso.numpy()\n",
    "        poly = poly1.reshape((int(len(poly1)/2),2))\n",
    "        polygons.append(Polygon(poly))\n",
    "        color.append(c)\n",
    "\n",
    "    p = PatchCollection(polygons, facecolor = 'none', linewidths = 0, alpha = 0.4)\n",
    "    ax.add_collection(p)\n",
    "    p = PatchCollection(polygons, facecolor = 'none', edgecolors = color, linewidths = 2)\n",
    "    ax.add_collection(p)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transform(img, target, mean_std = ([0., 0., 0.], [1., 1., 1.]),\n",
    "                   to_bgr255 = True, \n",
    "                   hflip_prob = 0, vflip_prob = 0, \n",
    "                   rot_prob = 0):\n",
    "\n",
    "    max_size = max(img.size)\n",
    "    min_size = max(img.size)\n",
    "    \n",
    "    resi = Resize(min_size, max_size)\n",
    "    hori_flip = RandomHorizontalFlip(prob = hflip_prob)\n",
    "    toten = ToTensor()\n",
    "    norm = Normalize(mean_std[0], mean_std[1], to_bgr255)\n",
    "\n",
    "    # own\n",
    "    rot = Rotate(prob = rot_prob)\n",
    "    veri_flip = VerticalFlip(prob = vflip_prob)\n",
    "    \n",
    "    transform = Compose([resi, hori_flip, veri_flip, rot,\n",
    "                         toten, norm])\n",
    "    new_img, new_target = transform(img, target)\n",
    "    \n",
    "    img_array = np.transpose(new_img.numpy(), (1, 2, 0))\n",
    "    cv2.imwrite('pic.jpeg', img_array)\n",
    "    show_image = mpimg.imread('pic.jpeg')\n",
    "    show_instances(show_image, new_target)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getitem_coco(image, ann_file, mean_std = ([0., 0., 0.],[1., 1., 1.]), \n",
    "                 hflip_prob = 0, vflip_prob = 0, rotation_angle = 0):\n",
    "    \n",
    "    data = json.load(open(ann_file))\n",
    "    coco = COCO(ann_file)\n",
    "    anno = [obj for obj in data['annotations'] if obj['iscrowd'] == 0]\n",
    "    \n",
    "    # boxes\n",
    "    boxes = [obj['bbox'] for obj in anno]\n",
    "    boxes = torch.as_tensor(boxes).reshape(-1,4)\n",
    "    \n",
    "    img = Image.open(image)\n",
    "    target = Box(boxes, img.size, mode = 'xywh').convert('xyxy')\n",
    "    \n",
    "    classes = [obj['category_id'] for obj in data['annotations']]\n",
    "    \n",
    "    json_category_id_to_contiguous_id = {\n",
    "            v: i + 1 for i, v in enumerate(coco.getCatIds())\n",
    "    }\n",
    "    classes = [json_category_id_to_contiguous_id[c] for c in classes]\n",
    "    classes = torch.tensor(classes)\n",
    "\n",
    "    target.add_field('labels', classes)\n",
    "\n",
    "    masks = [obj[\"segmentation\"] for obj in anno]\n",
    "    masks = SegmentationMask(masks, img.size)\n",
    "    target.add_field(\"masks\", masks)\n",
    "    target = target.clip_to_image(remove_empty=True)\n",
    "    \n",
    "    \n",
    "    # original image\n",
    "    show_instances(img, target)   \n",
    "    \n",
    "    for i in range(8):\n",
    "        make_transform(img, target, mean_std = mean_std, hflip_prob = 0, vflip_prob = 0, rot_prob = 1)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    make_transform(img, target, mean_std = mean_std, hflip_prob = 1, vflip_prob = 0, rotation_angle = 0)\n",
    "    make_transform(img, target, mean_std = mean_std, hflip_prob = 1, vflip_prob = 1, rotation_angle = 0)\n",
    "    make_transform(img, target, mean_std = mean_std, hflip_prob = 0, vflip_prob = 1, rotation_angle = 0)\n",
    "    make_transform(img, target, mean_std = mean_std, hflip_prob = 0, vflip_prob = 0, rotation_angle = 270)\n",
    "    make_transform(img, target, mean_std = mean_std, hflip_prob = 0, vflip_prob = 0, rotation_angle = 90)\n",
    "    make_transform(img, target, mean_std = mean_std, hflip_prob = 0, vflip_prob = 1, rotation_angle = 270)\n",
    "    make_transform(img, target, mean_std = mean_std, hflip_prob = 0, vflip_prob = 1, rotation_angle = 90)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def s():\n",
    "    getitem_coco('/home/max/github/ms2/test_augmentation/Raw_Nuclei_510.png', \n",
    "             '/home/max/github/ms2/test_augmentation/testing_raw_510.json', \n",
    "             hflip_prob = 0, vflip_prob = 0, rotation_angle = 0)\n",
    "#s()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "cases = [i for i in range(1,8)]\n",
    "i = random.choice(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "mrcnn_b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
