{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "import labelbox2coco as lb2co\n",
    "import urllib.request as down\n",
    "import os\n",
    "\n",
    "# ROOT on Monod, folder to save data\n",
    "DATA = '/data/proj/smFISH/Students/Max_Senftleben/files'\n",
    "\n",
    "ROOT_DIR = '/home/max/mrcnn_b_work'\n",
    "#ROOT_DIR = \"/home/maxsen/DEEPL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_annotation(labeled_data):\n",
    "    \n",
    "    coco_output = labeled_data[:-5] + \"_coco.json\"\n",
    "    lb2co.from_json(labeled_data = labeled_data, coco_output=coco_output)\n",
    "    \n",
    "    if os.path.isfile(coco_output) == True: \n",
    "        print(\"remove temp file: \", labeled_data)\n",
    "        os.remove(labeled_data)\n",
    "    else:\n",
    "        print(\"file was not converted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_annotation(anno_dir, lbx_json, image_dir):\n",
    "    \n",
    "    # make split folder for images\n",
    "    train_dir = image_dir + \"/train/\"\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "\n",
    "    val_dir = image_dir + \"/val/\"\n",
    "    if not os.path.exists(val_dir):\n",
    "        os.makedirs(val_dir)\n",
    "        \n",
    "    test_dir = image_dir + \"/test/\"\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.makedirs(test_dir)\n",
    "    \n",
    "    # split 3/5 train, 1/5 val and 1/5 test\n",
    "    data = json.load(open(anno_dir + lbx_json))\n",
    "    anno_train = []\n",
    "    anno_val = []\n",
    "    anno_test = []\n",
    "    counter = 0\n",
    "    for one_img in data:\n",
    "        \n",
    "        # training set 3/5\n",
    "        if counter <= len(data) * 0.6:\n",
    "            \n",
    "            # download image\n",
    "            img_id = one_img[\"External ID\"]\n",
    "            name_ = train_dir + img_id\n",
    "            down.urlretrieve(one_img[\"Labeled Data\"], name_ + '.jpg')\n",
    "            print(\"downloading file \", name_)\n",
    "            \n",
    "            # append to json list\n",
    "            anno_train.append(one_img)\n",
    "            counter += 1\n",
    "            \n",
    "        # validation set 1/5\n",
    "        elif counter <= len(data) * 0.8:\n",
    "            \n",
    "            # download image\n",
    "            img_id = one_img[\"External ID\"]\n",
    "            name_ = val_dir + img_id\n",
    "            down.urlretrieve(one_img[\"Labeled Data\"], name_ + '.jpg')\n",
    "            print(\"downloading file \", name_)\n",
    "            \n",
    "            # append to json list\n",
    "            anno_val.append(one_img)\n",
    "            counter += 1\n",
    "           \n",
    "        # test set 1/5\n",
    "        else:\n",
    "            \n",
    "            # download image\n",
    "            img_id = one_img[\"External ID\"]\n",
    "            name_ = test_dir + img_id\n",
    "            down.urlretrieve(one_img[\"Labeled Data\"], name_ + '.jpg')\n",
    "            print(\"downloading file \", name_)\n",
    "            \n",
    "            # append to json list\n",
    "            anno_test.append(one_img)\n",
    "            counter += 1\n",
    "    \n",
    "    temp_train = anno_dir + \"/train.json\"\n",
    "    with open(temp_train, \"w\") as wr:\n",
    "        json.dump(anno_train,wr, separators=(',', ':'))\n",
    "        print(\"convert \", temp_train)\n",
    "        \n",
    "    convert_annotation(temp_train)\n",
    "\n",
    "    temp_val = anno_dir + \"/val.json\"\n",
    "    with open(temp_val, \"w\") as wr:\n",
    "        json.dump(anno_val, wr, separators=(',', ':'))\n",
    "        print(\"convert \", temp_val)\n",
    "        \n",
    "    convert_annotation(temp_val)\n",
    "    \n",
    "    temp_test = anno_dir + \"/test.json\"\n",
    "    with open(temp_test, \"w\") as wr:\n",
    "        json.dump(anno_test, wr, separators=(',', ':'))\n",
    "        print(\"convert \", temp_test)\n",
    "        \n",
    "    convert_annotation(temp_test)\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specify filenames\n",
    "\n",
    "#anno_dir = ROOT_DIR + \"/annotation/new_nuclei\"\n",
    "#anno_dir = ROOT_DIR + \"/annotation/new_nuclei_mask\"\n",
    "anno_dir = DATA + \"/annotation/lbx_test\"\n",
    "\n",
    "#annotation_file = \"/nuclei_20190205.json\"\n",
    "#annotation_file = \"/nuclei_20190205_with_masks.json\"\n",
    "annotation_file = \"/box_wkt.json\"\n",
    "\n",
    "#img_dir = ROOT_DIR + \"/data/nuclei_20190205_data\"\n",
    "img_dir = DATA + \"/data/self_label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/train/2007_007698\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/train/2007_008714\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/train/2007_009807\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/train/2008_000033\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/train/2008_000074\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/train/2008_000162\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/train/2008_000187\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/train/2008_000197\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/train/2008_000336\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/train/2008_000399\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/train/2008_000595\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/train/2008_001030\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/train/2008_001274\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/train/2008_001632\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/train/2008_001716\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/train/2008_001719\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/train/2008_001761\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/val/2008_002215\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/val/2008_002221\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/val/2008_002551\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/val/2008_002710\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/val/2008_002719\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/test/2008_003083\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/test/2008_003094\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/test/2008_003101\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/test/2008_003196\n",
      "downloading file  /data/proj/smFISH/Students/Max_Senftleben/files/data/self_label/test/2008_003200\n",
      "convert  /data/proj/smFISH/Students/Max_Senftleben/files/annotation/lbx_test/train.json\n",
      "remove temp file:  /data/proj/smFISH/Students/Max_Senftleben/files/annotation/lbx_test/train.json\n",
      "convert  /data/proj/smFISH/Students/Max_Senftleben/files/annotation/lbx_test/val.json\n",
      "remove temp file:  /data/proj/smFISH/Students/Max_Senftleben/files/annotation/lbx_test/val.json\n",
      "convert  /data/proj/smFISH/Students/Max_Senftleben/files/annotation/lbx_test/test.json\n",
      "remove temp file:  /data/proj/smFISH/Students/Max_Senftleben/files/annotation/lbx_test/test.json\n"
     ]
    }
   ],
   "source": [
    "handle_annotation(anno_dir, annotation_file, img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Matterport_MaskRCNN",
   "language": "python",
   "name": "mat_mrcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
