{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-GPU training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.distributed.launch in order to get all GPUs to work\n",
    "# \n",
    "# python -m torch.distributed.launch \\\n",
    "# --nproc_per_node=$NGPUS \\\n",
    "# /path_to_maskrcnn_benchmark/tools/train_net.py \\\n",
    "# --config-file \"path/to/config/file.yaml\"\n",
    "# flag -m means that you run a library module as a script\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up custom environment before nearly anything else is imported\n",
    "# NOTE: this should be the first import (no not reorder)\n",
    "from maskrcnn_benchmark.utils.env import setup_environment  # noqa F401 isort:skip\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from maskrcnn_benchmark.config import cfg\n",
    "from maskrcnn_benchmark.data import make_data_loader\n",
    "from maskrcnn_benchmark.solver import make_lr_scheduler\n",
    "from maskrcnn_benchmark.solver import make_optimizer\n",
    "from maskrcnn_benchmark.engine.inference import inference\n",
    "from maskrcnn_benchmark.engine.trainer import do_train\n",
    "from maskrcnn_benchmark.modeling.detector import build_detection_model\n",
    "from maskrcnn_benchmark.utils.checkpoint import DetectronCheckpointer\n",
    "from maskrcnn_benchmark.utils.collect_env import collect_env_info\n",
    "from maskrcnn_benchmark.utils.comm import synchronize, get_rank\n",
    "from maskrcnn_benchmark.utils.imports import import_file\n",
    "from maskrcnn_benchmark.utils.logger import setup_logger\n",
    "from maskrcnn_benchmark.utils.miscellaneous import mkdir\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cfg, local_rank, distributed):\n",
    "    model = build_detection_model(cfg)\n",
    "    device = torch.device(cfg.MODEL.DEVICE)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = make_optimizer(cfg, model)\n",
    "    scheduler = make_lr_scheduler(cfg, optimizer)\n",
    "\n",
    "    if distributed:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(\n",
    "            model, device_ids=[local_rank], output_device=local_rank,\n",
    "            # this should be removed if we update BatchNorm stats\n",
    "            broadcast_buffers=False,\n",
    "        )\n",
    "\n",
    "    arguments = {}\n",
    "    arguments[\"iteration\"] = 0\n",
    "\n",
    "    output_dir = cfg.OUTPUT_DIR\n",
    "\n",
    "    save_to_disk = get_rank() == 0\n",
    "    checkpointer = DetectronCheckpointer(\n",
    "        cfg, model, optimizer, scheduler, output_dir, save_to_disk\n",
    "    )\n",
    "    extra_checkpoint_data = checkpointer.load(cfg.MODEL.WEIGHT)\n",
    "    arguments.update(extra_checkpoint_data)\n",
    "\n",
    "    data_loader = make_data_loader(\n",
    "        cfg,\n",
    "        is_train=True,\n",
    "        is_distributed=distributed,\n",
    "        start_iter=arguments[\"iteration\"],\n",
    "    )\n",
    "\n",
    "    checkpoint_period = cfg.SOLVER.CHECKPOINT_PERIOD\n",
    "\n",
    "    do_train(\n",
    "        model,\n",
    "        data_loader,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        checkpointer,\n",
    "        device,\n",
    "        checkpoint_period,\n",
    "        arguments,\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(cfg, model, distributed):\n",
    "    if distributed:\n",
    "        model = model.module\n",
    "    torch.cuda.empty_cache()  # TODO check if it helps\n",
    "    iou_types = (\"bbox\",)\n",
    "    if cfg.MODEL.MASK_ON:\n",
    "        iou_types = iou_types + (\"segm\",)\n",
    "    output_folders = [None] * len(cfg.DATASETS.TEST)\n",
    "    dataset_names = cfg.DATASETS.TEST\n",
    "    if cfg.OUTPUT_DIR:\n",
    "        for idx, dataset_name in enumerate(dataset_names):\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\", dataset_name)\n",
    "            mkdir(output_folder)\n",
    "            output_folders[idx] = output_folder\n",
    "    data_loaders_val = make_data_loader(cfg, is_train=False, is_distributed=distributed)\n",
    "    for output_folder, dataset_name, data_loader_val in zip(output_folders, dataset_names, data_loaders_val):\n",
    "        inference(\n",
    "            model,\n",
    "            data_loader_val,\n",
    "            dataset_name=dataset_name,\n",
    "            iou_types=iou_types,\n",
    "            box_only=cfg.MODEL.RPN_ONLY,\n",
    "            device=cfg.MODEL.DEVICE,\n",
    "            expected_results=cfg.TEST.EXPECTED_RESULTS,\n",
    "            expected_results_sigma_tol=cfg.TEST.EXPECTED_RESULTS_SIGMA_TOL,\n",
    "            output_folder=output_folder,\n",
    "        )\n",
    "        synchronize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"PyTorch Object Detection Training\")\n",
    "    parser.add_argument(\n",
    "        \"--config-file\",\n",
    "        default=\"\",\n",
    "        metavar=\"FILE\",\n",
    "        help=\"path to config file\",\n",
    "        type=str,\n",
    "    )\n",
    "    parser.add_argument(\"--local_rank\", type=int, default=0)\n",
    "    parser.add_argument(\n",
    "        \"--skip-test\",\n",
    "        dest=\"skip_test\",\n",
    "        help=\"Do not test the final model\",\n",
    "        action=\"store_true\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"opts\",\n",
    "        help=\"Modify config options using the command-line\",\n",
    "        default=None,\n",
    "        nargs=argparse.REMAINDER,\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    num_gpus = int(os.environ[\"WORLD_SIZE\"]) if \"WORLD_SIZE\" in os.environ else 1\n",
    "    args.distributed = num_gpus > 1\n",
    "\n",
    "    if args.distributed:\n",
    "        torch.cuda.set_device(args.local_rank)\n",
    "        torch.distributed.init_process_group(\n",
    "            backend=\"nccl\", init_method=\"env://\"\n",
    "        )\n",
    "        synchronize()\n",
    "\n",
    "    cfg.merge_from_file(args.config_file)\n",
    "    cfg.merge_from_list(args.opts)\n",
    "    cfg.freeze()\n",
    "\n",
    "    output_dir = cfg.OUTPUT_DIR\n",
    "    if output_dir:\n",
    "        mkdir(output_dir)\n",
    "\n",
    "    logger = setup_logger(\"maskrcnn_benchmark\", output_dir, get_rank())\n",
    "    logger.info(\"Using {} GPUs\".format(num_gpus))\n",
    "    logger.info(args)\n",
    "\n",
    "    logger.info(\"Collecting env info (might take some time)\")\n",
    "    logger.info(\"\\n\" + collect_env_info())\n",
    "\n",
    "    logger.info(\"Loaded configuration file {}\".format(args.config_file))\n",
    "    with open(args.config_file, \"r\") as cf:\n",
    "        config_str = \"\\n\" + cf.read()\n",
    "        logger.info(config_str)\n",
    "    logger.info(\"Running with config:\\n{}\".format(cfg))\n",
    "\n",
    "    model = train(cfg, args.local_rank, args.distributed)\n",
    "\n",
    "    if not args.skip_test:\n",
    "        test(cfg, model, args.distributed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--config-file FILE]\n",
      "                             [--local_rank LOCAL_RANK] [--skip-test]\n",
      "                             ...\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxsen/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrcnn_b",
   "language": "python",
   "name": "mrcnn_b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
