{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuclei Detect  demo\n",
    "\n",
    "This notebook can be used to predict cells and nuclei given one has the sufficient model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import random\n",
    "#import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib.image import imread\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are the relevant imports for the detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libcudart.so.10.0: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-77374d50feb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# importing the prediction class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNUCLEIdemo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git/nuclei_cell_detect/demo/predictor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmaskrcnn_benchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_detection_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmaskrcnn_benchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDetectronCheckpointer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmaskrcnn_benchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_list\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_image_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/nuclei_cell_detect/maskrcnn_benchmark/modeling/detector/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdetectors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_detection_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git/nuclei_cell_detect/maskrcnn_benchmark/modeling/detector/detectors.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgeneralized_rcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGeneralizedRCNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_DETECTION_META_ARCHITECTURES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"GeneralizedRCNN\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGeneralizedRCNN\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/nuclei_cell_detect/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmaskrcnn_benchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_list\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_image_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_backbone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_rpn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_roi_heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/nuclei_cell_detect/maskrcnn_benchmark/modeling/backbone/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_backbone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfbnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/nuclei_cell_detect/maskrcnn_benchmark/modeling/backbone/backbone.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmaskrcnn_benchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmaskrcnn_benchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_layers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_with_kaiming_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfpn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfpn_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/nuclei_cell_detect/maskrcnn_benchmark/modeling/make_layers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmaskrcnn_benchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmaskrcnn_benchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmaskrcnn_benchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoolers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPooler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/nuclei_cell_detect/maskrcnn_benchmark/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchNorm2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minterpolate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mroi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mROIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mroi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroi_align\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/nuclei_cell_detect/maskrcnn_benchmark/layers/nms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# from ._utils import _C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmaskrcnn_benchmark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libcudart.so.10.0: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "from maskrcnn_benchmark.config import cfg\n",
    "pylab.rcParams['figure.figsize'] = 20, 12\n",
    "\n",
    "# importing the prediction class\n",
    "from predictor import NUCLEIdemo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NUCLEIdemo class can load the config file and does the image prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration_file = \"../configs/nuclei_1gpu_nonorm_offline_res50.yaml\"\n",
    "#configuration_file = \"/home/max/github/nuclei_cell_detect/configs/nuclei_1gpu_nonorm_offline.yaml\"\n",
    "# update the config options with the config file\n",
    "cfg.merge_from_file(configuration_file)\n",
    "\n",
    "# manual override some options\n",
    "cfg.merge_from_list([\"MODEL.DEVICE\", \"cpu\"])\n",
    "\n",
    "# change dimensions of test images\n",
    "cfg.merge_from_list(['INPUT.MAX_SIZE_TEST','2049'])\n",
    "\n",
    "# change number of classes\n",
    "cfg.merge_from_list(['MODEL.ROI_BOX_HEAD.NUM_CLASSES','4'])\n",
    "\n",
    "# change normalization, here model was not normalized\n",
    "cfg.merge_from_list(['INPUT.PIXEL_MEAN', [0., 0., 0.]])\n",
    "\n",
    "# define model to use here\n",
    "cfg.merge_from_list(['MODEL.WEIGHT', '/data/proj/smFISH/Students/Max_Senftleben/files/models/20190310_offline_augment/model_final.pth'])\n",
    "cfg.merge_from_list(['OUTPUT_DIR', '.'])\n",
    "\n",
    "# define how many objects can be identified per image\n",
    "cfg.merge_from_list(['TEST.DETECTIONS_PER_IMG', '200'])\n",
    "\n",
    "# show the configuration\n",
    "#print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the confidence threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "def load(path):\n",
    "    pil_image = Image.open(path).convert(\"RGB\")\n",
    "    #print(pil_image)\n",
    "    # convert to BGR format\n",
    "    image = np.array(pil_image)[:, :, [2, 1, 0]]\n",
    "    return image\n",
    "\n",
    "def load_matplot(path):\n",
    "    img = imread(path)\n",
    "    return img\n",
    "\n",
    "def load_cv2(path):\n",
    "    img = cv2.imread(path,cv2.IMREAD_ANYDEPTH)\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    img = cv2.normalize(img, img, 0, 255, cv2.NORM_MINMAX)\n",
    "    img = np.uint8(img)\n",
    "    #img = cv2.convertScaleAbs(img)\n",
    "    return img\n",
    "\n",
    "def load_pil(path):\n",
    "    img = Image.open(path)\n",
    "    image = np.array(img)\n",
    "    \n",
    "    info = np.iinfo(image.dtype) # Get the information of the incoming image type\n",
    "    print(info)\n",
    "    data = image.astype(np.int32) / info.max # normalize the data to 0 - 1\n",
    "    data = 255 * data # Now scale by 255\n",
    "    img = data.astype(np.uint8)\n",
    "    cv2.imshow(\"Window\", img)\n",
    "    \n",
    "'''\n",
    "    >>> img = np.empty((100,100,1),dtype = np.uint16)\n",
    ">>> image = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "\n",
    ">>> cvuint8 = cv2.convertScaleAbs(image)\n",
    "\n",
    ">>> cvuint8.dtype\n",
    "dtype('uint8')\n",
    "    \n",
    "'''\n",
    "\n",
    "# show image alongside the result and save if necessary\n",
    "def imshow(img, result, save_path=None):\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax1.imshow(img)\n",
    "    plt.axis('off')\n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax2.imshow(result)\n",
    "    plt.axis('off')\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches = 'tight')\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "def imshow_single(result, save_path=None):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.imshow(result)\n",
    "    plt.axis('off')\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a few helper functions for loading images from a URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_detect = NUCLEIdemo(\n",
    "    cfg,\n",
    "    min_image_size=1024,\n",
    "    confidence_threshold=0.00000001,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the image paths and show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../../ms2/ssss/'\n",
    "#img_path = '/data/proj/smFISH/Students/Max_Senftleben/files/data/20190309_aug_pop/ss/'\n",
    "img_path = '/data/proj/smFISH/Simone/test_intron/AMEXP20181106/AMEXP20181106_hyb1/test_run_20181123_AMEXP20181106_hyb1_filtered_png/test_run_20181123_AMEXP20181106_hyb1_DAPI_filtered_png/'\n",
    "img_path = '/fish/simone_processing/simone_data/max_dapi_bf/EXP-19-CX9100_Excitatory_Hybridization15_DAPI/EXP-19-CX9100_Excitatory_Hybridization15_DAPI_filtered_png/'\n",
    "\n",
    "# random image is taken from the image path\n",
    "random_img = random.choice(os.listdir(img_path))\n",
    "image = load(img_path + random_img)\n",
    "image_matplot = load_matplot(img_path + random_img)\n",
    "image_cv2 = load_pil(img_path + random_img)\n",
    "\n",
    "print(type(image_cv2))\n",
    "print(image_cv2.shape)\n",
    "print(image_cv2.dtype)\n",
    "\n",
    "result, prediction = nuclei_detect.run_on_opencv_image(image_cv2)\n",
    "imshow(image_cv2, result)\n",
    "\n",
    "print(vars(prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_numpy(prediction, image, path):\n",
    "    list_masks = vars(prediction)['extra_fields']['mask']\n",
    "    masks_to_save = []\n",
    "    img = np.squeeze(np.dsplit(image,3)[0], axis=2)\n",
    "    masks_to_save.append(img)\n",
    "    # iterate through the list of masks\n",
    "    for i, label in enumerate(vars(prediction)['extra_fields']['labels']):\n",
    "        numpy_mask = list_masks[i].numpy().transpose(1,2,0)\n",
    "        numpy_mask = np.squeeze(numpy_mask, axis=2)\n",
    "        numpy_mask[numpy_mask > 0] = label\n",
    "        \n",
    "        masks_to_save.append(numpy_mask)\n",
    "    \n",
    "    np.save(path, np.dstack(masks_to_save))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for a folder of images\n",
    "img_path = '/data/proj/smFISH/Simone/test_intron/AMEXP20181106/AMEXP20181106_hyb1/test_run_20181123_AMEXP20181106_hyb1_filtered_png/test_run_20181123_AMEXP20181106_hyb1_DAPI_filtered_png/'\n",
    "save_results = '/data/proj/smFISH/Students/Max_Senftleben/files/results/'\n",
    "save_independently = save_results + '20190329_test_run_20181123_AMEXP20181106_hyb1_DAPI_filtered_png/'\n",
    "save_npy = save_results + '20190329_test_run_20181123_AMEXP20181106_hyb1_DAPI_filtered_npy/'\n",
    "\n",
    "# done on cpu to check if there is a difference in prediction\n",
    "save_independently_cpu = '/data/proj/smFISH/Students/Max_Senftleben/files/results/20190331_AMEXP20181106_DAPI_filtered_predicted_with_cpu/'\n",
    "\n",
    "def save_pred_as_numpy():\n",
    "    \n",
    "    for one_image in os.listdir(img_path):\n",
    "        print(\"Image {} is handled.\".format(one_image))\n",
    "        image = load_cv2(img_path + one_image)\n",
    "\n",
    "        # normalization ca be applied\n",
    "        result, prediction = nuclei_detect.run_on_opencv_image(image)\n",
    "        img = Image.fromarray(result)\n",
    "        img.save(save_independently + one_image[:-4] + '_pred.png')\n",
    "        make_numpy(prediction, image, save_npy + one_image[:-4] + '_pred.npy')\n",
    "        #imshow(image, result)\n",
    "        \n",
    "#main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_numpy(prediction, image_cv2, 'test.npy')\n",
    "\n",
    "# check numpy files\n",
    "save_npy = '/data/proj/smFISH/Students/Max_Senftleben/files/results/20190329_test_run_20181123_AMEXP20181106_hyb1_DAPI_filtered_npy/'\n",
    "random_img = random.choice(os.listdir(save_npy))\n",
    "mask = np.load(save_npy+random_img)\n",
    "mask_list = np.dsplit(mask, mask.shape[2])\n",
    "#for i in mask_list:\n",
    "    #print(i)\n",
    "    #plt.imshow(np.squeeze(i, axis=2))\n",
    "    #plt.show()\n",
    "    #print(np.unique(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunking_labeled_images(number_chunks_dimension, old_chunks, new_chunks):\n",
    "    for i in os.listdir(old_chunks):\n",
    "        mask = np.load(old_chunks + i)\n",
    "        \n",
    "        height, width = mask.shape[:2]\n",
    "        instance_count = mask.shape[2]\n",
    "        #masklist = np.dsplit(mask, instance_count)\n",
    "        #plt.imshow(np.dstack((masklist[1]*100, masklist[1]*100, masklist[1]*100)))\n",
    "        #plt.show()\n",
    "        \n",
    "        hsplits = np.split(mask,number_chunks_dimension,axis=0)\n",
    "        total_images = []\n",
    "        for split in hsplits:\n",
    "                total_images.append(np.split(split,number_chunks_dimension,axis=1))\n",
    "        total_images = [img for cpl in total_images for img in cpl] \n",
    "        \n",
    "        for idx,image_chunk in enumerate(total_images):\n",
    "            image_chunks_ids = []\n",
    "            mask = image_chunk != 0\n",
    "            planes_to_keep = np.flatnonzero((mask).sum(axis=(0,1)))\n",
    "            # Make sure that the image has labeled objects\n",
    "            if planes_to_keep.size:\n",
    "                image_chunk_trimmed = image_chunk[:,:,planes_to_keep]\n",
    "                image_chunk_trimmed_id = new_chunks + i.split('.')[0]+'chunk'+str(idx)\n",
    "        \n",
    "\n",
    "                np.save(image_chunk_trimmed_id, image_chunk_trimmed)\n",
    "        \n",
    "        \n",
    "    '''\n",
    "        mask = np.zeros([height, width, instance_count],\n",
    "                        dtype=np.uint8)\n",
    "\n",
    "        class_ids = []\n",
    "        mask_layer = 0\n",
    "        for lab, pgs in polygons.items():\n",
    "            \n",
    "            # Get the class id\n",
    "            class_id = class_names.index(lab)\n",
    "\n",
    "            for obj_num, coords in pgs.items():\n",
    "                \n",
    "                rr, cc = skimage.draw.polygon(coords[:,0], coords[:,1])\n",
    "                mask[rr, cc, mask_layer] = class_id\n",
    "                mask_layer += 1\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "\n",
    "        class_ids = np.array(class_ids)\n",
    "\n",
    "        # account for colored images\n",
    "        if image.shape[2] > 1:\n",
    "            print('ss')\n",
    "            dstack = np.dsplit(image,3)\n",
    "            stack1 = dstack[0][:, :, 0]\n",
    "            stack2 = dstack[1][:, :, 0]\n",
    "            stack3 = dstack[2][:, :, 0]\n",
    "            image_mask = np.insert(mask, 0, stack1, axis=2)\n",
    "            image_mask = np.insert(image_mask, 0, stack2, axis=2)\n",
    "            image_mask = np.insert(image_mask, 0, stack3, axis=2)\n",
    "        else:\n",
    "            image_mask = np.insert(mask,0,image,axis=2)\n",
    "        \n",
    "        print(image_mask.shape)\n",
    "        sstack = np.dsplit(image_mask, image_mask.shape[2])\n",
    "        plt.imshow(np.dstack((sstack[2], sstack[1], sstack[0])))\n",
    "        plt.show()\n",
    "        \n",
    "        # stack image with masks\n",
    "\n",
    "        # consider that we are collecting square images and only even number of cuts\n",
    "        hsplits = np.split(image_mask,number_chunks_dimension,axis=0)\n",
    "        total_images = []\n",
    "        for split in hsplits:\n",
    "                total_images.append(np.split(split,number_chunks_dimension,axis=1))\n",
    "        total_images = [img for cpl in total_images for img in cpl] \n",
    "\n",
    "        # Chunk the images and the segmented data\n",
    "        for idx,image_chunk in enumerate(total_images):\n",
    "            image_chunks_ids = []\n",
    "            mask = image_chunk != 0\n",
    "            planes_to_keep = np.flatnonzero((mask).sum(axis=(0,1)))\n",
    "            # Make sure that the image has labeled objects\n",
    "            if planes_to_keep.size:\n",
    "                image_chunk_trimmed = image_chunk[:,:,planes_to_keep]\n",
    "                image_chunk_trimmed_id = image_id.split('.')[0]+'chunk'+str(idx)\n",
    "\n",
    "                np.save(chunked_dir + image_chunk_trimmed_id, image_chunk_trimmed)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = '/data/proj/smFISH/Students/Max_Senftleben/files/results/20190329_test_run_20181123_AMEXP20181106_hyb1_DAPI_filtered_npy/'\n",
    "new = '/data/proj/smFISH/Students/Max_Senftleben/files/data/20190422_AMEX_transfer_nuclei/npy/'\n",
    "dim = 2\n",
    "\n",
    "chunking_labeled_images(dim, old, new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "mrcnn_b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
