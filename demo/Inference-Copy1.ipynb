{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "from predictor import NUCLEIdemo\n",
    "from predictor_coco import COCODemo\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from maskrcnn_benchmark.config import cfg\n",
    "import os\n",
    "import torch\n",
    "from maskrcnn_benchmark.config.paths_catalog import DatasetCatalog\n",
    "from maskrcnn_benchmark.utils.imports import import_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increasing the size of figures\n",
    "#pylab.rcParams['figure.figsize'] = 20, 12\n",
    "\n",
    "CONFIGS = '../configs/'\n",
    "#CONFIGS = '/home/maxsen/git/ms2/code/configs/'\n",
    "#CONFIGS = '/home/max/github/ms2/code/configs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config file\n",
    "\n",
    "config_file = CONFIGS + 'nuclei_1gpu_nonorm_offline.yaml'\n",
    "#config_file = CONFIGS + 'poly_t_1gpu_nonorm.yaml'\n",
    "cfg.merge_from_file(config_file)\n",
    "cfg.merge_from_list(['MODEL.DEVICE', 'cpu'])\n",
    "cfg.merge_from_list(['PATHS_CATALOG', '../maskrcnn_benchmark/config/paths_catalog.py'])\n",
    "\n",
    "# change dimensions of test images\n",
    "cfg.merge_from_list(['INPUT.MAX_SIZE_TEST','2049'])\n",
    "\n",
    "# change normalization, here model was not normalized\n",
    "cfg.merge_from_list(['INPUT.PIXEL_MEAN', [0., 0., 0.]])\n",
    "\n",
    "# define model to use here\n",
    "# if new, it may have to be set in paths_catalog.py\n",
    "cfg.merge_from_list(['MODEL.WEIGHT', '/home/maxsen/DEEPL/models_new/20190313_offline_augment/model_final.pth'])\n",
    "#print(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the model loader, for nuclei do NUCLEIdemo\n",
    "nuclei_detect = NUCLEIdemo(\n",
    "    cfg,\n",
    "    min_image_size = 512,\n",
    "    confidence_threshold=0.2,\n",
    "    show_mask_heatmaps = False\n",
    ")\n",
    "\n",
    "# pass categories (nuclei)\n",
    "nuclei_cat = [\n",
    "        \"__background\",\n",
    "        \"nuclei\",\n",
    "        \"undefined\",\n",
    "        \"clusters\"]\n",
    "\n",
    "# pass categories (poly-t)\n",
    "poly_cat = [\n",
    "        \"__background\",\n",
    "        \"Cell\",\n",
    "        \"Undefined\",\n",
    "        \"Clusters\",\n",
    "        \"Junk\"]\n",
    "\n",
    "categories_to_pass = nuclei_cat\n",
    "nuclei_detect.CATEGORIES = categories_to_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a subplot with predictions (green) vs ground truth (red) of the boxes and masks\n",
    "#predictions = nuclei_detect.inference(add_class_names = None, save_path = None,\n",
    "#                                     save_independently = save_independently)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for image in os.listdir(image_folder):\\n    pil_img = Image.open(image_folder + image)\\n    plt.imshow(pil_img)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do on test images(self, image_folder, result_folder = None, add_class_names = None):\n",
    "#image_folder = '/home/maxsen/DEEPL/data/training_data/Nuclei-Test_used_for_test/'\n",
    "#image_folder = '/data/proj/smFISH/Simone/test_intron/AMEXP20181106/AMEXP20181106_hyb1/test_run_20181123_AMEXP20181106_hyb1_filtered_png/test_run_20181123_AMEXP20181106_hyb1_DAPI_filtered_png/'\n",
    "#image_folder = '/home/maxsen/DEEPL/data/nuclei_20190205_data/all/'\n",
    "image_folder = '/home/maxsen/git/ms2/ssss/'\n",
    "result_folder = '/home/maxsen/DEEPL/data/training_data/res/'\n",
    "result_folder = '/data/proj/smFISH/Students/Max_Senftleben/files/results/20190329_test_run_20181123_AMEXP20181106_hyb1_DAPI_filtered_png/'\n",
    "\n",
    "'''for image in os.listdir(image_folder):\n",
    "    pil_img = Image.open(image_folder + image)\n",
    "    plt.imshow(pil_img)\n",
    "'''    \n",
    "#predictions = nuclei_detect.on_test_images(image_folder, result_folder = None, add_class_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsave_results = '/data/proj/smFISH/Students/Max_Senftleben/files/results/'\\nsave_independently = save_results + '20190329_test_run_20181123_AMEXP20181106_hyb1_DAPI_filtered_png/'\\n\\nsave_independently = '/data/proj/smFISH/Simone/test_intron/AMEXP20181106/AMEXP20181106_hyb1/test_run_20181123_AMEXP20181106_hyb1_filtered_png/test_run_20181123_AMEXP20181106_hyb1_DAPI_filtered_png/'\\n\\nfor i in os.listdir(save_independently):\\n    import matplotlib.pyplot as plt\\n    import matplotlib.image as mpimg\\n    #img=mpimg.imread(save_independently + i)\\n    #imgplot = plt.imshow(img)\\n    #plt.show()\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "save_results = '/data/proj/smFISH/Students/Max_Senftleben/files/results/'\n",
    "save_independently = save_results + '20190329_test_run_20181123_AMEXP20181106_hyb1_DAPI_filtered_png/'\n",
    "\n",
    "save_independently = '/data/proj/smFISH/Simone/test_intron/AMEXP20181106/AMEXP20181106_hyb1/test_run_20181123_AMEXP20181106_hyb1_filtered_png/test_run_20181123_AMEXP20181106_hyb1_DAPI_filtered_png/'\n",
    "\n",
    "for i in os.listdir(save_independently):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.image as mpimg\n",
    "    #img=mpimg.imread(save_independently + i)\n",
    "    #imgplot = plt.imshow(img)\n",
    "    #plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop image\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "\n",
    "margin = 300\n",
    "def do():\n",
    "    \n",
    "    for image in os.listdir(result_folder):\n",
    "        if not image.endswith(\"_hist.png\"):\n",
    "\n",
    "            original = Image.open(result_folder + image)\n",
    "            #original.show()\n",
    "\n",
    "            width, height = original.size   # Get dimensions\n",
    "\n",
    "            left = 150\n",
    "            top = 0\n",
    "            right = 750\n",
    "            bottom = 600\n",
    "            cropped_example = original.crop((left, top, right, bottom))\n",
    "\n",
    "            cropped_example.save(result_folder + image)\n",
    "#do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import plotly.plotly as py\n",
    "#import plotly.tools as tls\n",
    "import random\n",
    "\n",
    "def histogram(image_name, scores, labels, save_path = None):\n",
    "    \n",
    "    # get scores\n",
    "    all_scores = []\n",
    "    set_labels = sorted(set(labels))\n",
    "    for i in set_labels:\n",
    "        temp = []\n",
    "        for s in range(len(scores)):\n",
    "            if labels[s] == i:\n",
    "                temp.append(scores[s])\n",
    "        all_scores.append(temp)\n",
    "    \n",
    "    # make plot\n",
    "    \n",
    "    fig = plt.figure(dpi=150)\n",
    "    ax = fig.add_subplot(111)\n",
    "    bins = np.linspace(0, 1, 100)\n",
    "    for c, category in enumerate(all_scores):\n",
    "        plt.hist(category, bins, alpha = 1, \n",
    "                 label = 'Number of {}: {}'.format(list(set_labels)[c], len(category)))\n",
    "    plt.legend(loc = 'upper left')\n",
    "    plt.title('Frequency distribution confidence for {}'.format(image_name))\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path + image_name[:-4] + '_hist.png')\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confidence scores\n",
    "result_path = '/data/proj/smFISH/Students/Max_Senftleben/files/results/20190318_poly_t/'\n",
    "#result_path = '/home/maxsen/DEEPL/inference_polyt/'\n",
    "def histo():\n",
    "    \n",
    "    for file_name in predictions:\n",
    "\n",
    "        scores = predictions[file_name].get_field(\"scores\").tolist()\n",
    "        labels = predictions[file_name].get_field(\"labels\").tolist()\n",
    "        labels = [categories_to_pass[i] for i in labels]\n",
    "        histogram(file_name, scores, labels, save_path = save_independently)\n",
    "#histo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pdf\n",
    "\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter,A4\n",
    "from reportlab.platypus import SimpleDocTemplate,Table,PageBreak, Paragraph, Spacer, Image\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.lib.enums import TA_RIGHT\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib.styles import ParagraphStyle\n",
    "\n",
    "def pdf(result_path, pdf_save_path, title):\n",
    "    \n",
    "    styles = getSampleStyleSheet()\n",
    "    style_right = ParagraphStyle(name='right', parent=styles['Normal'], alignment=TA_RIGHT)\n",
    "    doc = SimpleDocTemplate(pdf_save_path, topMargin=10)\n",
    "    Story = []\n",
    "\n",
    "    # specify title\n",
    "    Story.append(Paragraph(title, styles['Title']))\n",
    "    \n",
    "    a=4\n",
    "    b=4\n",
    "    c=3\n",
    "    print(c)\n",
    "\n",
    "    \n",
    "    \n",
    "    image_names = set([i[:-9] for i in os.listdir(result_path)])\n",
    "    for image in image_names:\n",
    "        tb_data_line1 = [[ \n",
    "                Image(result_path + image + '_trut.png',a*inch, a*inch,hAlign=\"MIDDLE\"),\n",
    "                Image(result_path + image + '_bbox.png',   a*inch, a*inch,hAlign=\"LEFT\")\n",
    "                ]]\n",
    "        tb1 = Table(tb_data_line1)\n",
    "        Story.append(tb1)\n",
    "        \n",
    "        tb_data_line2 = [[ \n",
    "                Image(result_path + image + '_mask.png',a*inch, b*inch,hAlign=\"RIGHT\"),\n",
    "                Image(result_path + image + '_hist.png',   b*inch, c*inch,hAlign=\"LEFT\")\n",
    "                ]]\n",
    "        tb2 = Table(tb_data_line2)\n",
    "        Story.append(tb2)\n",
    "        \n",
    "        Story.append(PageBreak())\n",
    "    doc.build(Story)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf(save_independently, '/home/max/github/ms2/nuclei_inference.pdf', 'Nuclei segmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "mrcnn_b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
