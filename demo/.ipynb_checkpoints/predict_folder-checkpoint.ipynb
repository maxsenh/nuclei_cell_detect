{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do prediction on a whole folder and create stacked Numpy files for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import random\n",
    "#import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib.image import imread\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are the relevant imports for the detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libcudart.so.10.0: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-77374d50feb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# importing the prediction class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNUCLEIdemo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git/nuclei_cell_detect/demo/predictor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmaskrcnn_benchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_detection_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmaskrcnn_benchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDetectronCheckpointer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmaskrcnn_benchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_list\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_image_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/nuclei_cell_detect/maskrcnn_benchmark/modeling/detector/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdetectors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_detection_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git/nuclei_cell_detect/maskrcnn_benchmark/modeling/detector/detectors.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgeneralized_rcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGeneralizedRCNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_DETECTION_META_ARCHITECTURES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"GeneralizedRCNN\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGeneralizedRCNN\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/nuclei_cell_detect/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmaskrcnn_benchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_list\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_image_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_backbone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_rpn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_roi_heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/nuclei_cell_detect/maskrcnn_benchmark/modeling/backbone/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_backbone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfbnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/nuclei_cell_detect/maskrcnn_benchmark/modeling/backbone/backbone.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmaskrcnn_benchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmaskrcnn_benchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_layers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_with_kaiming_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfpn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfpn_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/nuclei_cell_detect/maskrcnn_benchmark/modeling/make_layers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmaskrcnn_benchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmaskrcnn_benchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmaskrcnn_benchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoolers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPooler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/nuclei_cell_detect/maskrcnn_benchmark/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchNorm2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minterpolate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mroi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mROIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mroi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroi_align\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/nuclei_cell_detect/maskrcnn_benchmark/layers/nms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# from ._utils import _C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmaskrcnn_benchmark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libcudart.so.10.0: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "from maskrcnn_benchmark.config import cfg\n",
    "pylab.rcParams['figure.figsize'] = 20, 12\n",
    "\n",
    "# importing the prediction class\n",
    "from predictor import NUCLEIdemo\n",
    "\n",
    "# make sure that pytorch is installed correctly, check\n",
    "# https://github.com/rusty1s/pytorch_geometric/issues/114\n",
    "# for troubleshooting if CUDA errors occur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NUCLEIdemo class can load the config file and does the image prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: False\n",
      "  NUM_WORKERS: 4\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "DATASETS:\n",
      "  TEST: ('coco_offline_augmented_test',)\n",
      "  TRAIN: ('coco_offline_augmented_train', 'coco_offline_augmented_val')\n",
      "INPUT:\n",
      "  HEIGHT_IS_WIDTH: False\n",
      "  MAX_SIZE_TEST: 2049\n",
      "  MAX_SIZE_TRAIN: 1025\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (1024,)\n",
      "  ONLINE_AUGMENT: False\n",
      "  PIXEL_MEAN: [0.0, 0.0, 0.0]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  TO_BGR255: True\n",
      "MODEL:\n",
      "  BACKBONE:\n",
      "    CONV_BODY: R-50-FPN\n",
      "    FREEZE_CONV_BODY_AT: 2\n",
      "    USE_GN: False\n",
      "  CLS_AGNOSTIC_BBOX_REG: False\n",
      "  DEVICE: cpu\n",
      "  FBNET:\n",
      "    ARCH: default\n",
      "    ARCH_DEF: \n",
      "    BN_TYPE: bn\n",
      "    DET_HEAD_BLOCKS: []\n",
      "    DET_HEAD_LAST_SCALE: 1.0\n",
      "    DET_HEAD_STRIDE: 0\n",
      "    DW_CONV_SKIP_BN: True\n",
      "    DW_CONV_SKIP_RELU: True\n",
      "    KPTS_HEAD_BLOCKS: []\n",
      "    KPTS_HEAD_LAST_SCALE: 0.0\n",
      "    KPTS_HEAD_STRIDE: 0\n",
      "    MASK_HEAD_BLOCKS: []\n",
      "    MASK_HEAD_LAST_SCALE: 0.0\n",
      "    MASK_HEAD_STRIDE: 0\n",
      "    RPN_BN_TYPE: \n",
      "    RPN_HEAD_BLOCKS: 0\n",
      "    SCALE_FACTOR: 1.0\n",
      "    WIDTH_DIVISOR: 1\n",
      "  FPN:\n",
      "    USE_GN: False\n",
      "    USE_RELU: False\n",
      "  GROUP_NORM:\n",
      "    DIM_PER_GP: -1\n",
      "    EPSILON: 1e-05\n",
      "    NUM_GROUPS: 32\n",
      "  KEYPOINT_ON: False\n",
      "  MASK_ON: True\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  RESNETS:\n",
      "    BACKBONE_OUT_CHANNELS: 256\n",
      "    NUM_GROUPS: 1\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_FUNC: StemWithFixedBatchNorm\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    TRANS_FUNC: BottleneckWithFixedBatchNorm\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n",
      "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
      "    BBOX_REG_BETA: 0.11\n",
      "    BBOX_REG_WEIGHT: 4.0\n",
      "    BG_IOU_THRESHOLD: 0.4\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    INFERENCE_TH: 0.05\n",
      "    LOSS_ALPHA: 0.25\n",
      "    LOSS_GAMMA: 2.0\n",
      "    NMS_TH: 0.4\n",
      "    NUM_CLASSES: 81\n",
      "    NUM_CONVS: 4\n",
      "    OCTAVE: 2.0\n",
      "    PRE_NMS_TOP_N: 1000\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCALES_PER_OCTAVE: 3\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_C5: True\n",
      "  RETINANET_ON: False\n",
      "  ROI_BOX_HEAD:\n",
      "    CONV_HEAD_DIM: 256\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    NUM_CLASSES: 4\n",
      "    NUM_STACKED_CONVS: 4\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    PREDICTOR: FPNPredictor\n",
      "    USE_GN: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    BG_IOU_THRESHOLD: 0.5\n",
      "    DETECTIONS_PER_IMG: 100\n",
      "    FG_IOU_THRESHOLD: 0.5\n",
      "    NMS: 0.5\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    SCORE_THRESH: 0.05\n",
      "    USE_FPN: True\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    NUM_CLASSES: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_SCALES: (0.0625,)\n",
      "    PREDICTOR: KeypointRCNNPredictor\n",
      "    RESOLUTION: 14\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: True\n",
      "  ROI_MASK_HEAD:\n",
      "    CONV_LAYERS: (256, 256, 256, 256)\n",
      "    DILATION: 1\n",
      "    FEATURE_EXTRACTOR: MaskRCNNFPNFeatureExtractor\n",
      "    MLP_HEAD_DIM: 1024\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 2\n",
      "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
      "    POSTPROCESS_MASKS: False\n",
      "    POSTPROCESS_MASKS_THRESHOLD: 0.5\n",
      "    PREDICTOR: MaskRCNNC4Predictor\n",
      "    RESOLUTION: 28\n",
      "    SHARE_BOX_FEATURE_EXTRACTOR: False\n",
      "    USE_GN: False\n",
      "  RPN:\n",
      "    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n",
      "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
      "    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BG_IOU_THRESHOLD: 0.3\n",
      "    FG_IOU_THRESHOLD: 0.7\n",
      "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
      "    FPN_POST_NMS_TOP_N_TRAIN: 2000\n",
      "    MIN_SIZE: 0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOP_N_TEST: 1000\n",
      "    POST_NMS_TOP_N_TRAIN: 2000\n",
      "    PRE_NMS_TOP_N_TEST: 1000\n",
      "    PRE_NMS_TOP_N_TRAIN: 2000\n",
      "    RPN_HEAD: SingleConvRPNHead\n",
      "    STRADDLE_THRESH: 0\n",
      "    USE_FPN: True\n",
      "  RPN_ONLY: False\n",
      "  WEIGHT: /home/maxsen/DEEPL/model_final.pth\n",
      "OUTPUT_DIR: .\n",
      "PATHS_CATALOG: /home/maxsen/git/nuclei_cell_detect/maskrcnn_benchmark/config/paths_catalog.py\n",
      "SOLVER:\n",
      "  BASE_LR: 0.00125\n",
      "  BIAS_LR_FACTOR: 2\n",
      "  CHECKPOINT_PERIOD: 2500\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 1\n",
      "  MAX_ITER: 720000\n",
      "  MOMENTUM: 0.9\n",
      "  STEPS: (480000, 640000)\n",
      "  WARMUP_FACTOR: 0.3333333333333333\n",
      "  WARMUP_ITERS: 500\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0\n",
      "TENSORBOARD_EXPERIMENT: .\n",
      "TEST:\n",
      "  DETECTIONS_PER_IMG: 200\n",
      "  EXPECTED_RESULTS: []\n",
      "  EXPECTED_RESULTS_SIGMA_TOL: 4\n",
      "  IMS_PER_BATCH: 1\n"
     ]
    }
   ],
   "source": [
    "configuration_file = \"../configs/nuclei_1gpu_nonorm_offline_res50.yaml\"\n",
    "\n",
    "# update the config options with the config file\n",
    "cfg.merge_from_file(configuration_file)\n",
    "\n",
    "# manual override some options\n",
    "\n",
    "cfg.merge_from_list([\"MODEL.DEVICE\", \"cpu\"])\n",
    "\n",
    "# change dimensions of test images\n",
    "cfg.merge_from_list(['INPUT.MAX_SIZE_TEST','2049'])\n",
    "\n",
    "# change number of classes (classes + 1 for background)\n",
    "cfg.merge_from_list(['MODEL.ROI_BOX_HEAD.NUM_CLASSES','4'])\n",
    "\n",
    "# change normalization, here model was not normalized\n",
    "cfg.merge_from_list(['INPUT.PIXEL_MEAN', [0., 0., 0.]])\n",
    "\n",
    "# define model for prediction to use here\n",
    "cfg.merge_from_list(['MODEL.WEIGHT', '/home/maxsen/DEEPL/model_final.pth'])\n",
    "cfg.merge_from_list(['OUTPUT_DIR', '.'])\n",
    "\n",
    "# show the configuration\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple ways of loading and plotting of images\n",
    "\n",
    "For my purposes, load_cv2 was best because it took into account all formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "def load(path):\n",
    "    pil_image = Image.open(path).convert(\"RGB\")\n",
    "    #print(pil_image)\n",
    "    # convert to BGR format\n",
    "    image = np.array(pil_image)[:, :, [2, 1, 0]]\n",
    "    return image\n",
    "\n",
    "def load_matplot(path):\n",
    "    img = imread(path)\n",
    "    return img\n",
    "\n",
    "def load_cv2(path):\n",
    "    img = cv2.imread(path,cv2.IMREAD_ANYDEPTH)\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    img = cv2.normalize(img, img, 0, 255, cv2.NORM_MINMAX)\n",
    "    img = np.uint8(img)\n",
    "    #img = cv2.convertScaleAbs(img)\n",
    "    return img\n",
    "\n",
    "def load_pil(path):\n",
    "    img = Image.open(path)\n",
    "    image = np.array(img)\n",
    "    \n",
    "    info = np.iinfo(image.dtype) # Get the information of the incoming image type\n",
    "    print(info)\n",
    "    data = image.astype(np.int32) / info.max # normalize the data to 0 - 1\n",
    "    data = 255 * data # Now scale by 255\n",
    "    img = data.astype(np.uint8)\n",
    "    cv2.imshow(\"Window\", img)\n",
    "    \n",
    "\n",
    "# show image alongside the result and save if necessary\n",
    "def imshow(img, result, save_path=None):\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax1.imshow(img)\n",
    "    plt.axis('off')\n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax2.imshow(result)\n",
    "    plt.axis('off')\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches = 'tight')\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "def imshow_single(result, save_path=None):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.imshow(result)\n",
    "    plt.axis('off')\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NUCLEIdemo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2aa30b4a197a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# here the image size and the confidence threshold can be changed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m nuclei_detect = NUCLEIdemo(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmin_image_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mconfidence_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00000001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NUCLEIdemo' is not defined"
     ]
    }
   ],
   "source": [
    "# here the image size and the confidence threshold can be changed\n",
    "nuclei_detect = NUCLEIdemo(\n",
    "    cfg,\n",
    "    min_image_size=1024,\n",
    "    confidence_threshold=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the image paths and do the prediction on the whole folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make stacked numpy file from its prediction and the ground truth\n",
    "# where the first dimension is the numpy file and every other is the numpy \n",
    "\n",
    "def make_numpy(prediction, image, path):\n",
    "    \n",
    "    # get the masks from the prediction variable\n",
    "    list_masks = vars(prediction)['extra_fields']['mask']\n",
    "    masks_to_save = []\n",
    "    \n",
    "    # ground truth image\n",
    "    img = np.squeeze(np.dsplit(image,3)[0], axis=2)\n",
    "    masks_to_save.append(img)\n",
    "    \n",
    "    # iterate through the list of masks\n",
    "    for i, label in enumerate(vars(prediction)['extra_fields']['labels']):\n",
    "        numpy_mask = list_masks[i].numpy().transpose(1,2,0)\n",
    "        numpy_mask = np.squeeze(numpy_mask, axis=2)\n",
    "        numpy_mask[numpy_mask > 0] = label\n",
    "        \n",
    "        masks_to_save.append(numpy_mask)\n",
    "    \n",
    "    # save the numpy array\n",
    "    np.save(path, np.dstack(masks_to_save))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for a folder of images\n",
    "\n",
    "# folder of handled images\n",
    "img_path = '/data/proj/smFISH/Simone/test_intron/AMEXP20181106/AMEXP20181106_hyb1/test_run_20181123_AMEXP20181106_hyb1_filtered_png/test_run_20181123_AMEXP20181106_hyb1_DAPI_filtered_png/'\n",
    "\n",
    "# path to subfolder for the results\n",
    "save_results = '/data/proj/smFISH/Students/Max_Senftleben/files/results/'\n",
    "\n",
    "# path to save the images with their masks\n",
    "save_independently = save_results + '20190329_test_run_20181123_AMEXP20181106_hyb1_DAPI_filtered_png/'\n",
    "\n",
    "# path to save the predicted stacked numpy files\n",
    "save_npy = save_results + '20190329_test_run_20181123_AMEXP20181106_hyb1_DAPI_filtered_npy/'\n",
    "\n",
    "def save_pred_as_numpy():\n",
    "    \n",
    "    for one_image in os.listdir(img_path):\n",
    "        print(\"Image {} is handled.\".format(one_image))\n",
    "        image = load_cv2(img_path + one_image)\n",
    "\n",
    "        # prediction is done\n",
    "        result, prediction = nuclei_detect.run_on_opencv_image_original(image)\n",
    "        img = Image.fromarray(result)\n",
    "        \n",
    "        # png image is saved with masks (for visualization)\n",
    "        img.save(save_independently + one_image[:-4] + '_pred.png')\n",
    "        # numpy files are saved\n",
    "        make_numpy(prediction, image, save_npy + one_image[:-4] + '_pred.npy')\n",
    "        \n",
    "        # optionally, the results can be shown\n",
    "        #imshow(image, result)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check predicted numpy files\n",
    "# can also be used to check the chunks from below\n",
    "random_img = random.choice(os.listdir(save_npy))\n",
    "mask = np.load(save_npy+random_img)\n",
    "mask_list = np.dsplit(mask, mask.shape[2])\n",
    "\n",
    "'''\n",
    "for i in mask_list:\n",
    "    print(i)\n",
    "    plt.imshow(np.squeeze(i, axis=2))\n",
    "    plt.show()\n",
    "    print(np.unique(i))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy arrays from above have the size of the original image\n",
    "# here, the arrays can be sliced so that they can be used in training in the next step\n",
    "# after this step, the chunks can further be used in the creation of the data set\n",
    "def chunking_labeled_images(number_chunks_dimension, old_chunks, new_chunks):\n",
    "    for i in os.listdir(old_chunks):\n",
    "        mask = np.load(old_chunks + i)\n",
    "        \n",
    "        height, width = mask.shape[:2]\n",
    "        instance_count = mask.shape[2]\n",
    "        #masklist = np.dsplit(mask, instance_count)\n",
    "        #plt.imshow(np.dstack((masklist[1]*100, masklist[1]*100, masklist[1]*100)))\n",
    "        #plt.show()\n",
    "        \n",
    "        hsplits = np.split(mask,number_chunks_dimension,axis=0)\n",
    "        total_images = []\n",
    "        for split in hsplits:\n",
    "                total_images.append(np.split(split,number_chunks_dimension,axis=1))\n",
    "        total_images = [img for cpl in total_images for img in cpl] \n",
    "        \n",
    "        for idx,image_chunk in enumerate(total_images):\n",
    "            image_chunks_ids = []\n",
    "            mask = image_chunk != 0\n",
    "            planes_to_keep = np.flatnonzero((mask).sum(axis=(0,1)))\n",
    "            # Make sure that the image has labeled objects\n",
    "            if planes_to_keep.size:\n",
    "                image_chunk_trimmed = image_chunk[:,:,planes_to_keep]\n",
    "                image_chunk_trimmed_id = new_chunks + i.split('.')[0]+'chunk'+str(idx)\n",
    "        \n",
    "\n",
    "                np.save(image_chunk_trimmed_id, image_chunk_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = '/data/proj/smFISH/Students/Max_Senftleben/files/results/20190329_test_run_20181123_AMEXP20181106_hyb1_DAPI_filtered_npy/'\n",
    "new = '/data/proj/smFISH/Students/Max_Senftleben/files/data/20190422_AMEX_transfer_nuclei/npy/'\n",
    "dim = 2\n",
    "\n",
    "chunking_labeled_images(dim, old, new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "mrcnn_b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
